{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ponTMmSSEZs",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "n2g6fdToSEZu",
    "outputId": "e11f26e1-058c-40f1-8c48-1f312ca96988"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "# general tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "import json \n",
    "\n",
    "\n",
    "# RDKit\n",
    "from rdkit import Chem, RDLogger\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global options\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DPFEM3G3nJvr"
   },
   "outputs": [],
   "source": [
    "# import functions written for this project\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version =  1.10.2+cu113\n",
      "Pytorch Geometric version =  2.0.3\n",
      "CUDA version =  11.3\n",
      "CUDA available =  False\n",
      "Random Pytorch test tensor =  tensor([0.0609])\n"
     ]
    }
   ],
   "source": [
    "# import and check funtionality of pytorch / pytorch geometric\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "print(\"Pytorch version = \", torch.__version__)\n",
    "print(\"Pytorch Geometric version = \", torch_geometric.__version__)\n",
    "print(\"CUDA version = \", torch.version.cuda)\n",
    "print(\"CUDA available = \", torch.cuda.is_available())\n",
    "print(\"Random Pytorch test tensor = \", torch.rand(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqtoXSSPnJvy",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to collect experimental settings\n",
    "settings_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose ChEMBL dopamine D2 data set\n",
    "\n",
    "datafolder_filepath = \"data/chembl_dopamine_d2/\"\n",
    "settings_dict[\"target_name\"] = \"chembl_dopamine_d2\"\n",
    "activity_type = \"Ki [nM]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or choose ChEMBL factor Xa data set\n",
    "\n",
    "datafolder_filepath = \"data/chembl_factor_xa/\"\n",
    "settings_dict[\"target_name\"] = \"chembl_factor_xa\"\n",
    "activity_type = \"Ki [nM]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or choose PostEra SARS-CoV 2 Mpro data set\n",
    "\n",
    "datafolder_filepath = \"data/postera_sars_cov_2_mpro/\"\n",
    "settings_dict[\"target_name\"] = \"postera_sars_cov_2_mpro\"\n",
    "activity_type = \"f_avg_IC50 [uM]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>f_avg_IC50 [uM]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCNC(=O)CN1CC2(CCN(c3cncc4ccccc34)C2=O)c2cc(Cl...</td>\n",
       "      <td>0.275118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C(CN1CC2(CCN(c3cncc4ccccc34)C2=O)c2cc(Cl)ccc...</td>\n",
       "      <td>0.202767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNC(=O)C1(N2C[C@]3(CCN(c4cncc5ccccc45)C3=O)c3c...</td>\n",
       "      <td>55.453947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNC(=O)C1(N2C[C@@]3(CCN(c4cncc5ccccc45)C3=O)c3...</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNC(=O)CN1C[C@@]2(CCN(c3cncc4ccccc34)C2=O)c2cc...</td>\n",
       "      <td>0.052757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>N#Cc1cc(Cl)cc(NC(=O)Nc2cccnc2)c1</td>\n",
       "      <td>99.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>N#Cc1cccc(NC(=O)Nc2cncc(N)c2)c1</td>\n",
       "      <td>54.272964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>N#Cc1cccc(NC(=O)Nc2c[nH]c3ncccc23)c1</td>\n",
       "      <td>63.554925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>N#Cc1cccc(NC(=O)Cc2cncc3ccccc23)c1</td>\n",
       "      <td>26.719515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>O=C(Cc1cncc2ccccc12)Nc1ccccc1</td>\n",
       "      <td>57.590417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1924 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SMILES  f_avg_IC50 [uM]\n",
       "0     CCNC(=O)CN1CC2(CCN(c3cncc4ccccc34)C2=O)c2cc(Cl...         0.275118\n",
       "1     O=C(CN1CC2(CCN(c3cncc4ccccc34)C2=O)c2cc(Cl)ccc...         0.202767\n",
       "2     CNC(=O)C1(N2C[C@]3(CCN(c4cncc5ccccc45)C3=O)c3c...        55.453947\n",
       "3     CNC(=O)C1(N2C[C@@]3(CCN(c4cncc5ccccc45)C3=O)c3...         0.050000\n",
       "4     CNC(=O)CN1C[C@@]2(CCN(c3cncc4ccccc34)C2=O)c2cc...         0.052757\n",
       "...                                                 ...              ...\n",
       "1919                   N#Cc1cc(Cl)cc(NC(=O)Nc2cccnc2)c1        99.010000\n",
       "1920                    N#Cc1cccc(NC(=O)Nc2cncc(N)c2)c1        54.272964\n",
       "1921               N#Cc1cccc(NC(=O)Nc2c[nH]c3ncccc23)c1        63.554925\n",
       "1922                 N#Cc1cccc(NC(=O)Cc2cncc3ccccc23)c1        26.719515\n",
       "1923                      O=C(Cc1cncc2ccccc12)Nc1ccccc1        57.590417\n",
       "\n",
       "[1924 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load clean data\n",
    "#display data from postera_sars_cov_2_mpro\n",
    "\n",
    "dataframe = pd.read_csv(datafolder_filepath + \"molecule_data_clean.csv\", sep = \",\")\n",
    "settings_dict[\"n_molecules\"] = len(dataframe)\n",
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_smiles =  (1924,)\n",
      "CCNC(=O)CN1CC2(CCN(c3cncc4ccccc34)C2=O)c2cc(Cl)ccc2S1(=O)=O\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7efcae525990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# construct array with SMILES strings\n",
    "\n",
    "x_smiles = dataframe[\"SMILES\"].values\n",
    "\n",
    "print(\"Shape of x_smiles = \", x_smiles.shape)\n",
    "print(x_smiles[0])\n",
    "display(Chem.MolFromSmiles(x_smiles[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "ZGTsCwA9nJwK",
    "outputId": "d9c43474-c7b7-4622-da65-6ebe36c9c3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value (y) =  -0.9180193183732708\n",
      "Standard deviation (y) =  1.04434733236911\n",
      "Maximum value (y) =  2.573819647563703\n",
      "Minimum value (y) =  -2.296665190261531\n",
      "Shape (y) =  (1924,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# construct array with activity labels y (via applying the negative decadic logarithm to the experimental activity measurements)\n",
    "\n",
    "y = -np.log10(dataframe[activity_type].values.astype(float))\n",
    "\n",
    "print(\"Mean value (y) = \", np.mean(y))\n",
    "print(\"Standard deviation (y) = \", np.std(y))\n",
    "print(\"Maximum value (y) = \", np.amax(y))\n",
    "print(\"Minimum value (y) = \", np.amin(y))\n",
    "print(\"Shape (y) = \", y.shape)\n",
    "plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iMep582hnJwL"
   },
   "outputs": [],
   "source": [
    "# create dictionary which maps SMILES strings to their activity labels\n",
    "\n",
    "x_smiles_to_y_dict = dict(list(zip(x_smiles, y)))\n",
    "# print(x_smiles_to_y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matched molecular pairs (MMPs) =  12594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles_1</th>\n",
       "      <th>smiles_2</th>\n",
       "      <th>transformation</th>\n",
       "      <th>constant_part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1cc(Br)ccc1Nc1cc(Cl)cc(CC(=O)Nc2cncc3ccccc2...</td>\n",
       "      <td>COc1ncc(Br)cc1Nc1cc(Cl)cc(CC(=O)Nc2cncc3ccccc2...</td>\n",
       "      <td>[*:1]c1ccc([*:2])c([*:3])c1&gt;&gt;[*:1]c1cnc([*:3])...</td>\n",
       "      <td>[*:1]Br.[*:2]Nc1cc(Cl)cc(CC(=O)Nc2cncc3ccccc23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C(Cc1cc(Cl)cc(NCc2ccc(Br)cc2)c1)Nc1cncc2ccccc12</td>\n",
       "      <td>COc1cc(Br)ccc1Nc1cc(Cl)cc(CC(=O)Nc2cncc3ccccc2...</td>\n",
       "      <td>[*:1]NCc1ccc([*:2])cc1&gt;&gt;[*:1]Nc1ccc([*:2])cc1OC</td>\n",
       "      <td>[*:2]Br.[*:1]c1cc(Cl)cc(CC(=O)Nc2cncc3ccccc23)c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O=C(Cc1cc(Cl)cc(NCc2ccc(Br)cc2)c1)Nc1cncc2ccccc12</td>\n",
       "      <td>COc1ncc(Br)cc1Nc1cc(Cl)cc(CC(=O)Nc2cncc3ccccc2...</td>\n",
       "      <td>[*:1]NCc1ccc([*:2])cc1&gt;&gt;[*:1]Nc1cc([*:2])cnc1OC</td>\n",
       "      <td>[*:2]Br.[*:1]c1cc(Cl)cc(CC(=O)Nc2cncc3ccccc23)c1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            smiles_1  \\\n",
       "0  COc1cc(Br)ccc1Nc1cc(Cl)cc(CC(=O)Nc2cncc3ccccc2...   \n",
       "1  O=C(Cc1cc(Cl)cc(NCc2ccc(Br)cc2)c1)Nc1cncc2ccccc12   \n",
       "2  O=C(Cc1cc(Cl)cc(NCc2ccc(Br)cc2)c1)Nc1cncc2ccccc12   \n",
       "\n",
       "                                            smiles_2  \\\n",
       "0  COc1ncc(Br)cc1Nc1cc(Cl)cc(CC(=O)Nc2cncc3ccccc2...   \n",
       "1  COc1cc(Br)ccc1Nc1cc(Cl)cc(CC(=O)Nc2cncc3ccccc2...   \n",
       "2  COc1ncc(Br)cc1Nc1cc(Cl)cc(CC(=O)Nc2cncc3ccccc2...   \n",
       "\n",
       "                                      transformation  \\\n",
       "0  [*:1]c1ccc([*:2])c([*:3])c1>>[*:1]c1cnc([*:3])...   \n",
       "1    [*:1]NCc1ccc([*:2])cc1>>[*:1]Nc1ccc([*:2])cc1OC   \n",
       "2    [*:1]NCc1ccc([*:2])cc1>>[*:1]Nc1cc([*:2])cnc1OC   \n",
       "\n",
       "                                       constant_part  \n",
       "0  [*:1]Br.[*:2]Nc1cc(Cl)cc(CC(=O)Nc2cncc3ccccc23...  \n",
       "1   [*:2]Br.[*:1]c1cc(Cl)cc(CC(=O)Nc2cncc3ccccc23)c1  \n",
       "2   [*:2]Br.[*:1]c1cc(Cl)cc(CC(=O)Nc2cncc3ccccc23)c1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matched molecular pair (MMP) dataframe\n",
    "\n",
    "dataframe_mmps = pd.read_csv(datafolder_filepath + \"MMP_data_clean.csv\",\n",
    "                             sep = \",\",\n",
    "                             header = 0)\n",
    "\n",
    "print(\"Number of matched molecular pairs (MMPs) = \", len(dataframe_mmps))\n",
    "display(dataframe_mmps.head(n = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_smiles_mmps =  (10832, 2)\n",
      "Shape of x_smiles_mmp_cores =  (10832,)\n",
      "Number of distinct cores =  741 \n",
      "\n",
      "Shape of y_mmps =  (10832,)\n",
      "Number of molecules =  1924\n",
      "Number of MMPs = non-ACs + half-cliffs + ACs =  12594\n",
      "Number of non-ACs with activity difference less than 1 order of magnitude =  10311\n",
      "Number of deleted half-cliffs with activity difference between 1 and 2 orders of magnitude =  1762\n",
      "Number of ACs with property difference larger than 2 orders of magnitude =  521\n",
      "Ratio of non-ACs to ACs =  19.791 : 1\n"
     ]
    }
   ],
   "source": [
    "# construct MMP array and binary MMP labels for AC-prediction (we delete half-cliffs)\n",
    "\n",
    "# create array with all MMPs (including half-cliffs)\n",
    "X_smiles_mmps = dataframe_mmps.values[:,0:2]\n",
    "\n",
    "# create array with all MMP cores\n",
    "x_smiles_mmp_cores = dataframe_mmps.values[:,3]\n",
    "\n",
    "# label ACs with 1 and other MMPs (= half-cliffs and non-ACs) with 0\n",
    "y_mmps = np.array([int(abs(x_smiles_to_y_dict[smiles_1] - x_smiles_to_y_dict[smiles_2]) >= 2) \n",
    "                   for [smiles_1, smiles_2] in X_smiles_mmps])\n",
    "\n",
    "# determine indices for MMPs which are half-cliffs (these should be deleted)\n",
    "y_mmps_half_cliffs = np.array([int(1 < abs(x_smiles_to_y_dict[smiles_1] - x_smiles_to_y_dict[smiles_2]) < 2) \n",
    "                               for [smiles_1, smiles_2] in X_smiles_mmps])\n",
    "ind_delete = np.ndarray.flatten(np.argwhere(y_mmps_half_cliffs > 0))\n",
    "\n",
    "# delete MMPs which are half-cliffs\n",
    "X_smiles_mmps = np.delete(X_smiles_mmps, ind_delete, axis = 0)\n",
    "settings_dict[\"n_mmps\"] = len(X_smiles_mmps)\n",
    "x_smiles_mmp_cores = np.delete(x_smiles_mmp_cores, ind_delete, axis = 0)\n",
    "y_mmps = np.delete(y_mmps, ind_delete)\n",
    "\n",
    "print(\"Shape of X_smiles_mmps = \", X_smiles_mmps.shape)\n",
    "print(\"Shape of x_smiles_mmp_cores = \", x_smiles_mmp_cores.shape)\n",
    "print(\"Number of distinct cores = \", len(set(x_smiles_mmp_cores)), \"\\n\")\n",
    "print(\"Shape of y_mmps = \", y_mmps.shape)\n",
    "print(\"Number of molecules = \", settings_dict[\"n_molecules\"])\n",
    "print(\"Number of MMPs = non-ACs + half-cliffs + ACs = \", len(dataframe_mmps))\n",
    "print(\"Number of non-ACs with activity difference less than 1 order of magnitude = \", np.sum(1 - y_mmps))\n",
    "print(\"Number of deleted half-cliffs with activity difference between 1 and 2 orders of magnitude = \", len(ind_delete))\n",
    "print(\"Number of ACs with property difference larger than 2 orders of magnitude = \", np.sum(y_mmps))\n",
    "print(\"Ratio of non-ACs to ACs = \", np.round(np.sum(1 - y_mmps)/np.sum(y_mmps), 3), \": 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "E3tpaPgInJwO",
    "outputId": "c54287fd-de4e-4cc5-b004-7cd22956c28f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_mmps_vals =  (10832, 2)\n"
     ]
    }
   ],
   "source": [
    "# construct array with activity values for mmps\n",
    "\n",
    "Y_mmps_vals = np.array([[x_smiles_to_y_dict[smiles_1], x_smiles_to_y_dict[smiles_2]] for [smiles_1, smiles_2] in X_smiles_mmps])\n",
    "print(\"Shape of Y_mmps_vals = \", Y_mmps_vals.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AWXtiK3LnJwP"
   },
   "outputs": [],
   "source": [
    "# randomly flip or maintain direction of all smiles pairs in X_smiles_mmps and Y_mmps_vals to make potency directionality classification balanced\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for k in range(len(X_smiles_mmps)):\n",
    "    if np.random.uniform(0,1) > 0.5:\n",
    "        \n",
    "        X_smiles_mmps[k, 0:2] = np.flip(X_smiles_mmps[k, 0:2])\n",
    "        Y_mmps_vals[k, 0:2] = np.flip(Y_mmps_vals[k, 0:2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "S0PaecYGnJwP",
    "outputId": "894f2407-c58d-449c-b283-6a2af099426e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_mmps_pd =  (10832,)\n",
      "Number of 1s =  4704\n"
     ]
    }
   ],
   "source": [
    "# construct potency directionality target variable (0: smiles_1 activity is larger than or equal to smiles_2 activity, 1: smiles_1 activity is smaller than smiles_2 activity)\n",
    "\n",
    "y_mmps_pd = np.array([int(val_1 < val_2) for [val_1, val_2] in Y_mmps_vals])\n",
    "\n",
    "print(\"Shape of y_mmps_pd = \", y_mmps_pd.shape)\n",
    "print(\"Number of 1s = \", np.sum(y_mmps_pd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uScaKIFnJwZ",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Prepare Data Split for Individual Compounds and MMPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DAqvC3EknJwZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create data split dictionary for k-fold cross validation repeated with m random seeds\n",
    "\n",
    "settings_dict[\"k_splits\"] = 2\n",
    "settings_dict[\"m_reps\"] = 3\n",
    "settings_dict[\"random_state_cv\"] = 42\n",
    "\n",
    "data_split_dictionary = create_data_split_dictionary_for_mols_and_mmps(x_smiles,\n",
    "                                                                       X_smiles_mmps,\n",
    "                                                                       x_smiles_mmp_cores,\n",
    "                                                                       k_splits = settings_dict[\"k_splits\"],\n",
    "                                                                       m_reps = settings_dict[\"m_reps\"],\n",
    "                                                                       random_state_cv = settings_dict[\"random_state_cv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>k</th>\n",
       "      <th>D_train</th>\n",
       "      <th>D_test</th>\n",
       "      <th>M_train_pos</th>\n",
       "      <th>M_train_neg</th>\n",
       "      <th>M_inter_pos</th>\n",
       "      <th>M_inter_neg</th>\n",
       "      <th>M_test_pos</th>\n",
       "      <th>M_test_neg</th>\n",
       "      <th>M_cores_pos</th>\n",
       "      <th>M_cores_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>*</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>962</td>\n",
       "      <td>962</td>\n",
       "      <td>72</td>\n",
       "      <td>2383</td>\n",
       "      <td>270</td>\n",
       "      <td>5143</td>\n",
       "      <td>179</td>\n",
       "      <td>2785</td>\n",
       "      <td>10</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>962</td>\n",
       "      <td>962</td>\n",
       "      <td>179</td>\n",
       "      <td>2785</td>\n",
       "      <td>270</td>\n",
       "      <td>5143</td>\n",
       "      <td>72</td>\n",
       "      <td>2383</td>\n",
       "      <td>14</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>962</td>\n",
       "      <td>962</td>\n",
       "      <td>140</td>\n",
       "      <td>2772</td>\n",
       "      <td>270</td>\n",
       "      <td>5209</td>\n",
       "      <td>111</td>\n",
       "      <td>2330</td>\n",
       "      <td>5</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>962</td>\n",
       "      <td>962</td>\n",
       "      <td>111</td>\n",
       "      <td>2330</td>\n",
       "      <td>270</td>\n",
       "      <td>5209</td>\n",
       "      <td>140</td>\n",
       "      <td>2772</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>962</td>\n",
       "      <td>962</td>\n",
       "      <td>153</td>\n",
       "      <td>2618</td>\n",
       "      <td>258</td>\n",
       "      <td>5095</td>\n",
       "      <td>110</td>\n",
       "      <td>2598</td>\n",
       "      <td>11</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>962</td>\n",
       "      <td>962</td>\n",
       "      <td>110</td>\n",
       "      <td>2598</td>\n",
       "      <td>258</td>\n",
       "      <td>5095</td>\n",
       "      <td>153</td>\n",
       "      <td>2618</td>\n",
       "      <td>11</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>962.0</td>\n",
       "      <td>962.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>2581.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>5149.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>2581.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>175.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     m  k D_train D_test M_train_pos M_train_neg M_inter_pos M_inter_neg  \\\n",
       "*    0  0     962    962          72        2383         270        5143   \n",
       "*    0  1     962    962         179        2785         270        5143   \n",
       "*    1  0     962    962         140        2772         270        5209   \n",
       "*    1  1     962    962         111        2330         270        5209   \n",
       "*    2  0     962    962         153        2618         258        5095   \n",
       "*    2  1     962    962         110        2598         258        5095   \n",
       "Avg  *  *   962.0  962.0       127.5      2581.0       266.0      5149.0   \n",
       "\n",
       "    M_test_pos M_test_neg M_cores_pos M_cores_neg  \n",
       "*          179       2785          10         163  \n",
       "*           72       2383          14         137  \n",
       "*          111       2330           5         190  \n",
       "*          140       2772           3         170  \n",
       "*          110       2598          11         195  \n",
       "*          153       2618          11         198  \n",
       "Avg      127.5     2581.0         9.0       175.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inspect high-level contents of data split dictionary\n",
    "\n",
    "inspect_data_split_dictionary(data_split_dictionary, y_mmps);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdqcFmuknJwZ",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Generate Molecular Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ECFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save/load x_smiles_to_fp_dict to txt file\n",
    "# import json \n",
    "# with open('x_smiles_to_fp_dict.txt', 'w') as file:\n",
    "#      file.write(json.dumps(x_smiles_to_fp_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ECFP hyperparameters\n",
    "settings_dict[\"radius\"] = 2\n",
    "settings_dict[\"bitstring_length\"] = 2**11\n",
    "settings_dict[\"use_features\"] = False\n",
    "settings_dict[\"use_chirality\"] = True\n",
    "\n",
    "# create dictionary that maps SMILES strings to ECFPs\n",
    "x_fp = {}\n",
    "\n",
    "for smiles in x_smiles:\n",
    "\n",
    "    x_fp.update({smiles : circular_fps_from_smiles(smiles,\n",
    "                                         radius = settings_dict[\"radius\"],\n",
    "                                         bitstring_length = settings_dict[\"bitstring_length\"],\n",
    "                                         use_features = settings_dict[\"use_features\"],\n",
    "                                         use_chirality = settings_dict[\"use_chirality\"]).tolist()})\n",
    "with open('smiles_fp_dict.txt', 'w') as file:\n",
    "    file.write(json.dumps(x_fp))\n",
    "\n",
    "x_smiles_to_fp_dict = x_fp\n",
    "# dict(list(zip(x_smiles, x_fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 14:55:09,516|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:55:16,444|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:55:16,448|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:16,652|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:16,658|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:55:23,065|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:55:23,069|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:23,260|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:23,265|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:55:31,215|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:55:31,218|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:31,401|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:31,407|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:55:39,176|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:55:39,178|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:39,359|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:39,365|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:55:44,902|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:55:44,905|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:45,077|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:45,082|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:55:50,712|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:55:50,715|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:50,894|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:50,900|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:55:58,956|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:55:58,959|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:59,154|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:55:59,159|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:56:05,312|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:56:05,313|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:05,505|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:05,511|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:56:11,851|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:56:11,852|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:12,053|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:12,058|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:56:19,644|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:56:19,647|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:19,842|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:19,848|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:56:31,238|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:56:31,240|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:31,437|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:31,443|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:56:37,501|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:56:37,504|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:37,690|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:37,696|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:56:44,468|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:56:44,469|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:44,661|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:44,667|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:56:51,143|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:56:51,144|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:51,339|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:51,345|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:56:57,321|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:56:57,324|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:57,513|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:56:57,518|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:57:03,717|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:57:03,718|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:57:03,903|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:57:03,909|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:57:09,633|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:57:09,635|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:57:09,799|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:57:09,804|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:57:45,755|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:57:45,757|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:57:45,954|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:57:45,960|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:57:50,146|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:57:50,149|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:57:50,286|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:57:50,291|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:57:57,226|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:57:57,227|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:57:57,391|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:57:57,396|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:58:04,123|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:58:04,124|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:58:04,288|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:58:04,293|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 14:58:08,346|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 14:58:08,349|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 14:58:08,486|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 14:58:08,492|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 15:07:12,375|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 15:07:12,379|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 15:07:12,766|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 15:07:12,771|INFO|Generating conformers for placeholder_name.\n",
      "2023-04-04 15:12:04,417|INFO|Generated 1 conformers for placeholder_name.\n",
      "2023-04-04 15:12:04,421|INFO|Generating fingerprints for placeholder_name.\n",
      "2023-04-04 15:12:04,669|INFO|Generated 1 fingerprints for placeholder_name.\n",
      "2023-04-04 15:12:04,675|INFO|Generating conformers for placeholder_name.\n"
     ]
    }
   ],
   "source": [
    "# # set ECFP hyperparameters\n",
    "# settings_dict[\"radius\"] = 2\n",
    "# settings_dict[\"bitstring_length\"] = 2**11\n",
    "# settings_dict[\"use_features\"] = False\n",
    "# settings_dict[\"use_chirality\"] = True\n",
    "\n",
    "# create dictionary that maps SMILES strings to ECFPs\n",
    "x_3fp = {}\n",
    "\n",
    "for smiles in x_smiles:\n",
    "\n",
    "    x_3fp.update({smiles: e3fp_from_smiles(smiles).tolist()})\n",
    "with open('smiles_3fp_dict.txt', 'w') as file:\n",
    "    file.write(json.dumps(x_3fp))\n",
    "\n",
    "# x_smiles_to_3fp_dict = dict(list(zip(x_smiles, x_3fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_smiles_to_3fp_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1718166/779798777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_smiles_to_3fp_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_smiles_to_3fp_dict' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PDVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values to replace =  0 ( 0.0 %)\n",
      "Shape of X_pdv =  (1924, 200)\n"
     ]
    }
   ],
   "source": [
    "# create PDVs\n",
    "settings_dict[\"descriptor_list\"] = None # use default 200 descriptors from literature\n",
    "\n",
    "X_pdv = list(range(settings_dict[\"n_molecules\"]))\n",
    "for (k, smiles) in enumerate(x_smiles):\n",
    "    X_pdv[k] = rdkit_mol_descriptors_from_smiles(smiles, descriptor_list = settings_dict[\"descriptor_list\"])\n",
    "X_pdv = np.array(X_pdv)\n",
    "\n",
    "# replace NaN with 0\n",
    "print(\"Number of NaN values to replace = \", np.sum(np.isnan(X_pdv)),\"(\",100*np.sum(np.isnan(X_pdv))/(X_pdv.shape[0]*X_pdv.shape[1]) ,r\"%)\")\n",
    "X_pdv = np.nan_to_num(X_pdv)\n",
    "print(\"Shape of X_pdv = \", X_pdv.shape)\n",
    "\n",
    "# create dictionary that maps SMILES strings to PDVs\n",
    "x_smiles_to_pdv_dict = dict(list(zip(x_smiles, X_pdv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Molecular Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(x_smiles_to_pdv_dict.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create molecular graphs as list of geometric data objects\n",
    "\n",
    "graph_list = create_pytorch_geometric_data_set_from_smiles_and_targets(x_smiles, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Experimentally Evaluate QSAR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6smSzqcnJwZ",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ECFP + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GMrprO3nJwZ"
   },
   "outputs": [],
   "source": [
    "# set directory for saving of experimental results\n",
    "\n",
    "settings_dict[\"method_name\"] = \"ecfp_rf\"\n",
    "filepath = \"results/\" + settings_dict[\"target_name\"] + \"/\" + settings_dict[\"method_name\"] + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOdCsIVAnJwb"
   },
   "outputs": [],
   "source": [
    "# hyperparameter- and random search settings\n",
    "\n",
    "settings_dict[\"j_splits\"] = 5\n",
    "settings_dict[\"h_iters\"] = 10\n",
    "settings_dict[\"random_search_scoring\"] = \"neg_mean_absolute_error\"\n",
    "settings_dict[\"random_search_verbose\"] = 1\n",
    "settings_dict[\"random_search_random_state\"] = 42\n",
    "settings_dict[\"random_search_n_jobs\"] = -1\n",
    "settings_dict[\"hyperparameter_grid\"] = {\"n_estimators\": [500], \n",
    "                                        \"max_depth\": [30, 40, 50, 60, 70, 80, 90, 100, 110, 120, None],\n",
    "                                        \"min_samples_split\": [2, 4, 6, 8, 10, 12],\n",
    "                                        \"min_samples_leaf\": [1, 2, 3, 4, 5, 6],\n",
    "                                        \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                        \"bootstrap\": [True, False],\n",
    "                                        \"random_state\": [42]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation via m-times repeated k-fold cross validation\n",
    "start_time = time.time()\n",
    "\n",
    "# preallocate dictionary with cubic arrays used to save prediction values and performance scores over all m*k experiments\n",
    "scores_dict = create_scores_dict(k_splits = settings_dict[\"k_splits\"], \n",
    "                                 m_reps = settings_dict[\"m_reps\"], \n",
    "                                 len_y = settings_dict[\"n_molecules\"])\n",
    "\n",
    "# train and evaluate models\n",
    "for (m, k) in data_split_dictionary.keys():\n",
    "    \n",
    "    # extract indices for D_train and D_test for this data split\n",
    "    (ind_train_mols, ind_test_mols) = data_split_dictionary[(m,k)][0:2]\n",
    "    \n",
    "    # generate training- and test data (for individual molecules)        \n",
    "    X_fp_train = np.array([x_smiles_to_fp_dict[smiles] for smiles in x_smiles[ind_train_mols]])\n",
    "    y_train = y[ind_train_mols]\n",
    "    \n",
    "    X_fp_test = np.array([x_smiles_to_fp_dict[smiles] for smiles in x_smiles[ind_test_mols]])\n",
    "    y_test = y[ind_test_mols]\n",
    "    \n",
    "    # instantiate fresh model\n",
    "    regressor = RandomizedSearchCV(estimator = RandomForestRegressor(),\n",
    "                                   param_distributions = settings_dict[\"hyperparameter_grid\"],\n",
    "                                   n_iter = settings_dict[\"h_iters\"],\n",
    "                                   cv = settings_dict[\"j_splits\"],\n",
    "                                   scoring = settings_dict[\"random_search_scoring\"],\n",
    "                                   verbose = settings_dict[\"random_search_verbose\"],\n",
    "                                   random_state = settings_dict[\"random_search_random_state\"],\n",
    "                                   n_jobs = settings_dict[\"random_search_n_jobs\"])\n",
    "    \n",
    "    # fit the model on the training data\n",
    "    regressor.fit(X_fp_train, y_train)\n",
    "    \n",
    "    # create and store qsar, ac, and pd-predictions\n",
    "    y_pred = regressor.predict(np.array([x_smiles_to_fp_dict[smiles] for smiles in x_smiles]))\n",
    "    create_and_store_qsar_ac_pd_results(scores_dict, x_smiles, X_smiles_mmps,\n",
    "                                        y, y_mmps, y_mmps_pd, y_pred,\n",
    "                                        data_split_dictionary, m, k)\n",
    "    \n",
    "    # give feedback on completion of this subexperiment\n",
    "    print(\"Subexperiment \", (m,k), \" completed. \\n\")\n",
    "\n",
    "# save experimental results\n",
    "save_qsar_ac_pd_results(filepath, scores_dict)\n",
    "\n",
    "# save experimental settings\n",
    "settings_dict[\"runtime\"] = str(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n",
    "save_experimental_settings(filepath, settings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display experimental results and settings\n",
    "display_experimental_results(filepath, decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfajdA2xnJwf",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ECFP + kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GN6Eky7QnJwg"
   },
   "outputs": [],
   "source": [
    "# set directory for saving of experimental results\n",
    "\n",
    "settings_dict[\"method_name\"] = \"ecfp_knn\"\n",
    "filepath = \"results/\" + settings_dict[\"target_name\"] + \"/\" + settings_dict[\"method_name\"] + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7JAlQJ-nJwh"
   },
   "outputs": [],
   "source": [
    "# hyperparameter- and random search settings\n",
    "\n",
    "settings_dict[\"j_splits\"] = 5\n",
    "settings_dict[\"h_iters\"] = 10\n",
    "settings_dict[\"random_search_scoring\"] = \"neg_mean_absolute_error\"\n",
    "settings_dict[\"random_search_verbose\"] = 1\n",
    "settings_dict[\"random_search_random_state\"] = 42\n",
    "settings_dict[\"random_search_n_jobs\"] = -1\n",
    "settings_dict[\"hyperparameter_grid\"] = {\"n_neighbors\": list(range(1, 101)),\n",
    "                                        \"weights\": [\"uniform\", \"distance\"],\n",
    "                                        \"p\": [1, 2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKyyrrYHnJwh",
    "outputId": "7360ef19-66c0-4bdd-a43f-017e1967335b"
   },
   "outputs": [],
   "source": [
    "# model evaluation via m-times repeated k-fold cross validation\n",
    "start_time = time.time()\n",
    "\n",
    "# preallocate dictionary with cubic arrays used to save prediction values and performance scores over all m*k experiments\n",
    "scores_dict = create_scores_dict(k_splits = settings_dict[\"k_splits\"], \n",
    "                                 m_reps = settings_dict[\"m_reps\"], \n",
    "                                 len_y = settings_dict[\"n_molecules\"])\n",
    "\n",
    "# train and evaluate models\n",
    "for (m, k) in data_split_dictionary.keys():\n",
    "    \n",
    "    # extract indices for D_train and D_test for this data split\n",
    "    (ind_train_mols, ind_test_mols) = data_split_dictionary[(m,k)][0:2]\n",
    "    \n",
    "    # generate training- and test data (mols)        \n",
    "    X_fp_train = np.array([x_smiles_to_fp_dict[smiles] for smiles in x_smiles[ind_train_mols]])\n",
    "    y_train = y[ind_train_mols]\n",
    "    \n",
    "    X_fp_test = np.array([x_smiles_to_fp_dict[smiles] for smiles in x_smiles[ind_test_mols]])\n",
    "    y_test = y[ind_test_mols]\n",
    "    \n",
    "    # instantiate fresh model\n",
    "    regressor = RandomizedSearchCV(estimator = KNeighborsRegressor(),\n",
    "                                   param_distributions = settings_dict[\"hyperparameter_grid\"],\n",
    "                                   n_iter = settings_dict[\"h_iters\"],\n",
    "                                   cv = settings_dict[\"j_splits\"],\n",
    "                                   scoring = settings_dict[\"random_search_scoring\"],\n",
    "                                   verbose = settings_dict[\"random_search_verbose\"],\n",
    "                                   random_state = settings_dict[\"random_search_random_state\"],\n",
    "                                   n_jobs = settings_dict[\"random_search_n_jobs\"])\n",
    "\n",
    "    # fit the model on the training data\n",
    "    regressor.fit(X_fp_train, y_train)\n",
    "    \n",
    "    # create and store qsar, ac, and pd-predictions\n",
    "    y_pred = regressor.predict(np.array([x_smiles_to_fp_dict[smiles] for smiles in x_smiles]))\n",
    "    create_and_store_qsar_ac_pd_results(scores_dict, x_smiles, X_smiles_mmps,\n",
    "                                        y, y_mmps, y_mmps_pd, y_pred,\n",
    "                                        data_split_dictionary, m, k)\n",
    "    \n",
    "    # give feedback on completion of this subexperiment\n",
    "    print(\"Subexperiment \", (m,k), \" completed. \\n\")\n",
    "\n",
    "# save experimental results\n",
    "save_qsar_ac_pd_results(filepath, scores_dict)\n",
    "\n",
    "# save experimental settings\n",
    "settings_dict[\"runtime\"] = str(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n",
    "save_experimental_settings(filepath, settings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Zf7j4gBnJwi",
    "outputId": "795f5101-6ca5-4508-c6a1-064d5579f001"
   },
   "outputs": [],
   "source": [
    "# display experimental results and settings\n",
    "display_experimental_results(filepath, decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ECFP + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GN6Eky7QnJwg"
   },
   "outputs": [],
   "source": [
    "# set directory for saving of experimental results\n",
    "\n",
    "settings_dict[\"method_name\"] = \"ecfp_mlp\"\n",
    "filepath = \"results/\" + settings_dict[\"target_name\"] + \"/\" + settings_dict[\"method_name\"] + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7JAlQJ-nJwh"
   },
   "outputs": [],
   "source": [
    "# hyperparameter- and optuna options\n",
    "\n",
    "settings_dict[\"optuna_options\"] = {\"h_iters\": 20,\n",
    "                                   \"frac_train\": 0.8,\n",
    "                                   \"data_splitting_seed\": 42,\n",
    "                                   \"performance_metric\": mean_absolute_error,\n",
    "                                   \"direction\": \"minimize\",\n",
    "                                   \"sampler\": optuna.samplers.TPESampler(), \n",
    "                                   \"pruner\": optuna.pruners.NopPruner()} \n",
    "\n",
    "settings_dict[\"mlp_hyperparameter_grid\"] = {\"architecture\": [arch(settings_dict[\"bitstring_length\"], 1, w, d) for (w,d) in all_combs_list([64, 128, 256, 512], [1, 5, 10])],\n",
    "                                          \"hidden_activation\": [nn.ReLU()],\n",
    "                                          \"output_activation\": [nn.Identity()],\n",
    "                                          \"use_bias\": [True],\n",
    "                                          \"hidden_dropout_rate\": [0, 0.25],\n",
    "                                          \"hidden_batchnorm\": [True]}\n",
    "\n",
    "settings_dict[\"train_hyperparameter_grid\"] = {\"batch_size\": [32, 64, 128],\n",
    "                                              \"dataloader_shuffle\": [True],\n",
    "                                              \"dataloader_drop_last\":[True],\n",
    "                                              \"learning_rate\": [1e-2, 1e-3],\n",
    "                                              \"lr_lambda\": [lambda epoch: max(0.95**epoch, 1e-2), lambda epoch: max(0.99**epoch, 1e-2)],\n",
    "                                              \"weight_decay\": [0.1, 0.01],\n",
    "                                              \"num_epochs\": [500],\n",
    "                                              \"loss_function\": [nn.MSELoss()],\n",
    "                                              \"optimiser\": [torch.optim.AdamW],\n",
    "                                              \"performance_metrics\": [\"regression\"],\n",
    "                                              \"print_results_per_epochs\": [None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKyyrrYHnJwh",
    "outputId": "7360ef19-66c0-4bdd-a43f-017e1967335b"
   },
   "outputs": [],
   "source": [
    "# model evaluation via m-times repeated k-fold cross validation\n",
    "start_time = time.time()\n",
    "\n",
    "# preallocate dictionary with cubic arrays used to save prediction values and performance scores over all m*k experiments\n",
    "scores_dict = create_scores_dict(k_splits = settings_dict[\"k_splits\"], \n",
    "                                 m_reps = settings_dict[\"m_reps\"], \n",
    "                                 len_y = settings_dict[\"n_molecules\"])\n",
    "\n",
    "# train and evaluate models\n",
    "for (m, k) in data_split_dictionary.keys():\n",
    "    \n",
    "    # extract indices for D_train and D_test for this data split\n",
    "    (ind_train_mols, ind_test_mols) = data_split_dictionary[(m,k)][0:2]\n",
    "    \n",
    "    # generate training- and test data (mols)\n",
    "    X_fp = np.array([x_smiles_to_fp_dict[smiles] for smiles in x_smiles])\n",
    "    \n",
    "    X_fp_train = np.array([x_smiles_to_fp_dict[smiles] for smiles in x_smiles[ind_train_mols]])\n",
    "    y_train = y[ind_train_mols]\n",
    "    Y_train = np.reshape(y_train, (-1, 1))\n",
    "    \n",
    "    X_fp_test = np.array([x_smiles_to_fp_dict[smiles] for smiles in x_smiles[ind_test_mols]])\n",
    "    y_test = y[ind_test_mols]\n",
    "    Y_test = np.reshape(y_test, (-1, 1))\n",
    "    \n",
    "    # create pytorch dataset objects for training and testing\n",
    "    dataset_train = TensorDataset(torch.tensor(X_fp_train, dtype = torch.float), torch.tensor(Y_train, dtype = torch.float))\n",
    "    dataset_test = TensorDataset(torch.tensor(X_fp_test, dtype = torch.float), torch.tensor(Y_test, dtype = torch.float))\n",
    "    \n",
    "    # find best hyperparameters via optuna and train associated model on training set\n",
    "    (regressor, \n",
    "     loss_curve_training_set) = train_mlps_via_optuna(dataset_train,\n",
    "                                                      settings_dict[\"optuna_options\"],\n",
    "                                                      settings_dict[\"mlp_hyperparameter_grid\"], \n",
    "                                                      settings_dict[\"train_hyperparameter_grid\"])\n",
    "    \n",
    "    # plot learning curves\n",
    "    plt.plot(loss_curve_training_set)\n",
    "    plt.title(\"loss curve on training set\")\n",
    "    plt.show()\n",
    "    \n",
    "    # create qsar predictions used to evaluate the model\n",
    "    y_pred = regressor(torch.tensor(X_fp, dtype = torch.float).to('cuda' if torch.cuda.is_available() else 'cpu')).cpu().detach().numpy()[:,0]\n",
    "    create_and_store_qsar_ac_pd_results(scores_dict, x_smiles, X_smiles_mmps,\n",
    "                                        y, y_mmps, y_mmps_pd, y_pred,\n",
    "                                        data_split_dictionary, m, k)\n",
    "    \n",
    "    # give feedback on completion of this subexperiment\n",
    "    print(\"Subexperiment \", (m,k), \" completed. \\n\")\n",
    "\n",
    "# save experimental results\n",
    "save_qsar_ac_pd_results(filepath, scores_dict)\n",
    "\n",
    "# save experimental settings\n",
    "settings_dict[\"runtime\"] = str(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n",
    "save_experimental_settings(filepath, settings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Zf7j4gBnJwi",
    "outputId": "795f5101-6ca5-4508-c6a1-064d5579f001"
   },
   "outputs": [],
   "source": [
    "# display experimental results and settings\n",
    "display_experimental_results(filepath, decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhPn8_4-nJwj",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PDV + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9mGLDz-nJwk"
   },
   "outputs": [],
   "source": [
    "# set directory for saving of experimental results\n",
    "\n",
    "settings_dict[\"method_name\"] = \"pdv_rf\"\n",
    "filepath = \"results/\" + settings_dict[\"target_name\"] + \"/\" + settings_dict[\"method_name\"] + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEZUbibknJwl"
   },
   "outputs": [],
   "source": [
    "# hyperparameter- and random search settings\n",
    "\n",
    "settings_dict[\"j_splits\"] = 5\n",
    "settings_dict[\"h_iters\"] = 10\n",
    "settings_dict[\"random_search_scoring\"] = \"neg_mean_absolute_error\"\n",
    "settings_dict[\"random_search_verbose\"] = 1\n",
    "settings_dict[\"random_search_random_state\"] = 42\n",
    "settings_dict[\"random_search_n_jobs\"] = -1\n",
    "settings_dict[\"hyperparameter_grid\"] = {\"n_estimators\": [500], \n",
    "                                        \"max_depth\": [30, 40, 50, 60, 70, 80, 90, 100, 110, 120, None],\n",
    "                                        \"min_samples_split\": [2, 4, 6, 8, 10, 12],\n",
    "                                        \"min_samples_leaf\": [1, 2, 3, 4, 5, 6],\n",
    "                                        \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                        \"bootstrap\": [True, False],\n",
    "                                        \"random_state\": [42]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFqHdI7LnJwl",
    "outputId": "81ba861e-ac69-4de9-b6c5-e9a39bf9b38e"
   },
   "outputs": [],
   "source": [
    "# model evaluation via m-times repeated k-fold cross validation\n",
    "start_time = time.time()\n",
    "\n",
    "# preallocate dictionary with cubic arrays used to save prediction values and performance scores over all m*k experiments\n",
    "scores_dict = create_scores_dict(k_splits = settings_dict[\"k_splits\"], \n",
    "                                 m_reps = settings_dict[\"m_reps\"], \n",
    "                                 len_y = settings_dict[\"n_molecules\"])\n",
    "\n",
    "# train and evaluate models\n",
    "for (m, k) in data_split_dictionary.keys():\n",
    "    \n",
    "    # extract indices for D_train and D_test for this data split\n",
    "    (ind_train_mols, ind_test_mols) = data_split_dictionary[(m,k)][0:2]\n",
    "    \n",
    "    # generate training- and test data (mols)        \n",
    "    X_pdv_train = X_pdv[ind_train_mols]\n",
    "    y_train = y[ind_train_mols]\n",
    "    \n",
    "    X_pdv_test = X_pdv[ind_test_mols]\n",
    "    y_test = y[ind_test_mols]\n",
    "    \n",
    "    # normalise data with empirical cumulative distribution functions for each feature (ecdf derived from training set)\n",
    "    (X_pdv_norm_train, normalisation_function) = normaliser_cdf(X_pdv_train)\n",
    "    X_pdv_norm_test = normalisation_function(X_pdv_test)\n",
    "    X_pdv_norm = normalisation_function(X_pdv)\n",
    "    \n",
    "    # instantiate fresh model\n",
    "    regressor = RandomizedSearchCV(estimator = RandomForestRegressor(),\n",
    "                                   param_distributions = settings_dict[\"hyperparameter_grid\"],\n",
    "                                   n_iter = settings_dict[\"h_iters\"],\n",
    "                                   cv = settings_dict[\"j_splits\"],\n",
    "                                   scoring = settings_dict[\"random_search_scoring\"],\n",
    "                                   verbose = settings_dict[\"random_search_verbose\"],\n",
    "                                   random_state = settings_dict[\"random_search_random_state\"],\n",
    "                                   n_jobs = settings_dict[\"random_search_n_jobs\"])\n",
    "\n",
    "    # fit the model on the training data\n",
    "    regressor.fit(X_pdv_norm_train, y_train)\n",
    "    \n",
    "    # create qsar predictions used to evaluate the model\n",
    "    y_pred = regressor.predict(X_pdv_norm)\n",
    "    create_and_store_qsar_ac_pd_results(scores_dict, x_smiles, X_smiles_mmps,\n",
    "                                        y, y_mmps, y_mmps_pd, y_pred,\n",
    "                                        data_split_dictionary, m, k)\n",
    "    \n",
    "    # give feedback on completion of this subexperiment\n",
    "    print(\"Subexperiment \", (m,k), \" completed. \\n\")\n",
    "\n",
    "# save experimental results\n",
    "save_qsar_ac_pd_results(filepath, scores_dict)\n",
    "\n",
    "# save experimental settings\n",
    "settings_dict[\"runtime\"] = str(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n",
    "save_experimental_settings(filepath, settings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYMeQfrrnJwm",
    "outputId": "c31ac760-a81f-4420-febf-3ef869f246f1"
   },
   "outputs": [],
   "source": [
    "# display experimental results and settings\n",
    "display_experimental_results(filepath, decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTPJp_6cnJwm",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PDV + kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynTBH9HPnJwm"
   },
   "outputs": [],
   "source": [
    "# set directory for saving of experimental results\n",
    "\n",
    "settings_dict[\"method_name\"] = \"pdv_knn\"\n",
    "filepath = \"results/\" + settings_dict[\"target_name\"] + \"/\" + settings_dict[\"method_name\"] + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yB2mOYdAnJwn"
   },
   "outputs": [],
   "source": [
    "# hyperparameter- and random search settings\n",
    "\n",
    "settings_dict[\"j_splits\"] = 5\n",
    "settings_dict[\"h_iters\"] = 10\n",
    "settings_dict[\"random_search_scoring\"] = \"neg_mean_absolute_error\"\n",
    "settings_dict[\"random_search_verbose\"] = 1\n",
    "settings_dict[\"random_search_random_state\"] = 42\n",
    "settings_dict[\"random_search_n_jobs\"] = -1\n",
    "settings_dict[\"hyperparameter_grid\"] = {\"n_neighbors\": list(range(1, 101)),\n",
    "                                        \"weights\": [\"uniform\", \"distance\"],\n",
    "                                        \"p\": [1, 2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AVif7dkInJwn",
    "outputId": "7491b0c2-fd9c-4c48-9617-37232f5a84c3"
   },
   "outputs": [],
   "source": [
    "# model evaluation via m-times repeated k-fold cross validation\n",
    "start_time = time.time()\n",
    "\n",
    "# preallocate dictionary with cubic arrays used to save prediction values and performance scores over all m*k experiments\n",
    "scores_dict = create_scores_dict(k_splits = settings_dict[\"k_splits\"], \n",
    "                                 m_reps = settings_dict[\"m_reps\"], \n",
    "                                 len_y = settings_dict[\"n_molecules\"])\n",
    "\n",
    "# train and evaluate models\n",
    "for (m, k) in data_split_dictionary.keys():\n",
    "    \n",
    "    # extract indices for D_train and D_test for this data split\n",
    "    (ind_train_mols, ind_test_mols) = data_split_dictionary[(m,k)][0:2]\n",
    "    \n",
    "    # generate training- and test data (mols)        \n",
    "    X_pdv_train = X_pdv[ind_train_mols]\n",
    "    y_train = y[ind_train_mols]\n",
    "    \n",
    "    X_pdv_test = X_pdv[ind_test_mols]\n",
    "    y_test = y[ind_test_mols]\n",
    "    \n",
    "    # normalise data with empirical cumulative distribution functions for each feature (ecdf derived from training set)\n",
    "    (X_pdv_norm_train, normalisation_function) = normaliser_cdf(X_pdv_train)\n",
    "    X_pdv_norm_test = normalisation_function(X_pdv_test)\n",
    "    X_pdv_norm = normalisation_function(X_pdv)\n",
    "    \n",
    "     # instantiate fresh model\n",
    "    regressor = RandomizedSearchCV(estimator = KNeighborsRegressor(),\n",
    "                                   param_distributions = settings_dict[\"hyperparameter_grid\"],\n",
    "                                   n_iter = settings_dict[\"h_iters\"],\n",
    "                                   cv = settings_dict[\"j_splits\"],\n",
    "                                   scoring = settings_dict[\"random_search_scoring\"],\n",
    "                                   verbose = settings_dict[\"random_search_verbose\"],\n",
    "                                   random_state = settings_dict[\"random_search_random_state\"],\n",
    "                                   n_jobs = settings_dict[\"random_search_n_jobs\"])\n",
    "\n",
    "    # fit the model on the training data\n",
    "    regressor.fit(X_pdv_norm_train, y_train)\n",
    "    \n",
    "    # create qsar predictions used to evaluate the model\n",
    "    y_pred = regressor.predict(X_pdv_norm)\n",
    "    create_and_store_qsar_ac_pd_results(scores_dict, x_smiles, X_smiles_mmps,\n",
    "                                        y, y_mmps, y_mmps_pd, y_pred,\n",
    "                                        data_split_dictionary, m, k)\n",
    "    \n",
    "    # give feedback on completion of this subexperiment\n",
    "    print(\"Subexperiment \", (m,k), \" completed. \\n\")\n",
    "\n",
    "# save experimental results\n",
    "save_qsar_ac_pd_results(filepath, scores_dict)\n",
    "\n",
    "# save experimental settings\n",
    "settings_dict[\"runtime\"] = str(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n",
    "save_experimental_settings(filepath, settings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLt4lV-vnJwo",
    "outputId": "0cb8b324-a0e2-4402-ca8a-35260719ae84"
   },
   "outputs": [],
   "source": [
    "# display experimental results and settings\n",
    "display_experimental_results(filepath, decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T904R4jAnJwp",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PDV + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzP-ACRRnJwp"
   },
   "outputs": [],
   "source": [
    "# set directory for saving of experimental results\n",
    "\n",
    "settings_dict[\"method_name\"] = \"pdv_mlp\"\n",
    "filepath = \"results/\" + settings_dict[\"target_name\"] + \"/\" + settings_dict[\"method_name\"] + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aQkXhCvnJwq"
   },
   "outputs": [],
   "source": [
    "# hyperparameter- and optuna options\n",
    "\n",
    "settings_dict[\"optuna_options\"] = {\"h_iters\": 20,\n",
    "                                   \"frac_train\": 0.8,\n",
    "                                   \"data_splitting_seed\": 42,\n",
    "                                   \"performance_metric\": mean_absolute_error,\n",
    "                                   \"direction\": \"minimize\",\n",
    "                                   \"sampler\": optuna.samplers.TPESampler(), \n",
    "                                   \"pruner\": optuna.pruners.NopPruner()} \n",
    "\n",
    "settings_dict[\"mlp_hyperparameter_grid\"] = {\"architecture\": [arch(200, 1, w, d) for (w,d) in all_combs_list([64, 128, 256, 512], [1, 5, 10])],\n",
    "                                          \"hidden_activation\": [nn.ReLU()],\n",
    "                                          \"output_activation\": [nn.Identity()],\n",
    "                                          \"use_bias\": [True],\n",
    "                                          \"hidden_dropout_rate\": [0, 0.25],\n",
    "                                          \"hidden_batchnorm\": [True]}\n",
    "\n",
    "settings_dict[\"train_hyperparameter_grid\"] = {\"batch_size\": [32, 64, 128],\n",
    "                                              \"dataloader_shuffle\": [True],\n",
    "                                              \"dataloader_drop_last\":[True],\n",
    "                                              \"learning_rate\": [1e-2, 1e-3],\n",
    "                                              \"lr_lambda\": [lambda epoch: max(0.95**epoch, 1e-2), lambda epoch: max(0.99**epoch, 1e-2)],\n",
    "                                              \"weight_decay\": [0.1, 0.01],\n",
    "                                              \"num_epochs\": [500],\n",
    "                                              \"loss_function\": [nn.MSELoss()],\n",
    "                                              \"optimiser\": [torch.optim.AdamW],\n",
    "                                              \"performance_metrics\": [\"regression\"],\n",
    "                                              \"print_results_per_epochs\": [None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVOMQzbwnJwq",
    "outputId": "192972eb-1dd8-4ca1-8e84-8e0a938e397e"
   },
   "outputs": [],
   "source": [
    "# model evaluation via m-times repeated k-fold cross validation\n",
    "start_time = time.time()\n",
    "\n",
    "# preallocate dictionary with cubic arrays used to save prediction values and performance scores over all m*k experiments\n",
    "scores_dict = create_scores_dict(k_splits = settings_dict[\"k_splits\"], \n",
    "                                 m_reps = settings_dict[\"m_reps\"], \n",
    "                                 len_y = settings_dict[\"n_molecules\"])\n",
    "\n",
    "# train and evaluate models\n",
    "for (m, k) in data_split_dictionary.keys():\n",
    "    \n",
    "    # extract indices for D_train and D_test for this data split\n",
    "    (ind_train_mols, ind_test_mols) = data_split_dictionary[(m,k)][0:2]\n",
    "    \n",
    "    # generate training- and test data (mols)        \n",
    "    X_pdv_train = X_pdv[ind_train_mols]\n",
    "    y_train = y[ind_train_mols]\n",
    "    Y_train = np.reshape(y_train, (-1, 1))\n",
    "    \n",
    "    X_pdv_test = X_pdv[ind_test_mols]\n",
    "    y_test = y[ind_test_mols]\n",
    "    Y_test = np.reshape(y_test, (-1, 1))\n",
    "    \n",
    "    # normalise data with empirical cumulative distribution functions for each feature (ecdf derived from training set)\n",
    "    (X_pdv_norm_train, normalisation_function) = normaliser_cdf(X_pdv_train)\n",
    "    X_pdv_norm_test = normalisation_function(X_pdv_test)\n",
    "    X_pdv_norm = normalisation_function(X_pdv)\n",
    "    \n",
    "    # create pytorch dataset objects for training and testing\n",
    "    dataset_train = TensorDataset(torch.tensor(X_pdv_norm_train, dtype = torch.float), torch.tensor(Y_train, dtype = torch.float))\n",
    "    dataset_test = TensorDataset(torch.tensor(X_pdv_norm_test, dtype = torch.float), torch.tensor(Y_test, dtype = torch.float))\n",
    "    \n",
    "    # find best hyperparameters via optuna and train associated model on training set\n",
    "    (regressor, \n",
    "     loss_curve_training_set) = train_mlps_via_optuna(dataset_train,\n",
    "                                                      settings_dict[\"optuna_options\"],\n",
    "                                                      settings_dict[\"mlp_hyperparameter_grid\"], \n",
    "                                                      settings_dict[\"train_hyperparameter_grid\"])\n",
    "    # plot learning curves\n",
    "    plt.plot(loss_curve_training_set)\n",
    "    plt.title(\"loss curve on training set\")\n",
    "    plt.show()\n",
    "    \n",
    "    # create qsar predictions used to evaluate the model\n",
    "    y_pred = regressor(torch.tensor(X_pdv_norm, dtype = torch.float).to('cuda' if torch.cuda.is_available() else 'cpu')).cpu().detach().numpy()[:,0]\n",
    "    create_and_store_qsar_ac_pd_results(scores_dict, x_smiles, X_smiles_mmps,\n",
    "                                        y, y_mmps, y_mmps_pd, y_pred,\n",
    "                                        data_split_dictionary, m, k)\n",
    "    \n",
    "    # give feedback on completion of this subexperiment\n",
    "    print(\"Subexperiment \", (m,k), \" completed. \\n\")\n",
    "\n",
    "# save experimental results\n",
    "save_qsar_ac_pd_results(filepath, scores_dict)\n",
    "\n",
    "# save experimental settings\n",
    "settings_dict[\"runtime\"] = str(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n",
    "save_experimental_settings(filepath, settings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83rJJtNXnJwr",
    "outputId": "c5c932f4-ebc0-4380-fd3d-d1691277f003"
   },
   "outputs": [],
   "source": [
    "# display experimental results and settings\n",
    "display_experimental_results(filepath, decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GIN + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzP-ACRRnJwp"
   },
   "outputs": [],
   "source": [
    "# set directory for saving of experimental results\n",
    "\n",
    "settings_dict[\"method_name\"] = \"gin_rf\"\n",
    "filepath = \"results/\" + settings_dict[\"target_name\"] + \"/\" + settings_dict[\"method_name\"] + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aQkXhCvnJwq"
   },
   "outputs": [],
   "source": [
    "# GNN + MLP: hyperparameter- and optuna settings\n",
    "\n",
    "settings_dict[\"optuna_options\"] = {\"h_iters\": 20,\n",
    "                                   \"frac_train\": 0.8,\n",
    "                                   \"data_splitting_seed\": 42,\n",
    "                                   \"performance_metric\": mean_absolute_error,\n",
    "                                   \"direction\": \"minimize\",\n",
    "                                   \"sampler\": optuna.samplers.TPESampler(), \n",
    "                                   \"pruner\": optuna.pruners.NopPruner()} \n",
    "\n",
    "settings_dict[\"gin_hyperparameter_grid\"] = {\"n_conv_layers\": [1, 2, 3],\n",
    "                                            \"input_dim\": [79],\n",
    "                                            \"hidden_dim\": [64, 128, 256],\n",
    "                                            \"mlp_n_hidden_layers\": [2],\n",
    "                                            \"mlp_hidden_activation\": [nn.ReLU()],\n",
    "                                            \"mlp_output_activation\": [nn.Identity()],\n",
    "                                            \"mlp_use_bias\": [True],\n",
    "                                            \"mlp_hidden_dropout_rate\": [0, 0.25],\n",
    "                                            \"mlp_hidden_batchnorm\": [True],\n",
    "                                            \"eps\": [0],\n",
    "                                            \"train_eps\": [False],\n",
    "                                            \"pooling_operation\": [global_max_pool]}\n",
    "\n",
    "settings_dict[\"mlp_hyperparameter_grid\"] = {\"architecture\": [arch(None, 1, w, d) for (w,d) in all_combs_list([None], [0])],\n",
    "                                            \"hidden_activation\": [nn.ReLU()],\n",
    "                                            \"output_activation\": [nn.Identity()],\n",
    "                                            \"use_bias\": [True],\n",
    "                                            \"hidden_dropout_rate\": [0],\n",
    "                                            \"hidden_batchnorm\": [True]}\n",
    "\n",
    "settings_dict[\"train_hyperparameter_grid\"] = {\"batch_size\": [32, 64, 128], \n",
    "                                              \"dataloader_shuffle\": [True],\n",
    "                                              \"dataloader_drop_last\":[True],\n",
    "                                              \"learning_rate\": [1e-2, 1e-3],\n",
    "                                              \"lr_lambda\": [lambda epoch: max(0.95**epoch, 1e-2), lambda epoch: max(0.99**epoch, 1e-2)],\n",
    "                                              \"weight_decay\": [0.1, 0.01],\n",
    "                                              \"num_epochs\": [500],\n",
    "                                              \"loss_function\": [nn.MSELoss()],\n",
    "                                              \"optimiser\": [torch.optim.AdamW],\n",
    "                                              \"performance_metrics\": [\"regression\"],\n",
    "                                              \"print_results_per_epochs\": [None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF: hyperparameter- and random search settings\n",
    "\n",
    "settings_dict[\"j_splits\"] = 5\n",
    "settings_dict[\"h_iters\"] = 10\n",
    "settings_dict[\"random_search_scoring\"] = \"neg_mean_absolute_error\"\n",
    "settings_dict[\"random_search_verbose\"] = 1\n",
    "settings_dict[\"random_search_random_state\"] = 42\n",
    "settings_dict[\"random_search_n_jobs\"] = -1\n",
    "settings_dict[\"hyperparameter_grid\"] = {\"n_estimators\": [500], \n",
    "                                        \"max_depth\": [30, 40, 50, 60, 70, 80, 90, 100, 110, 120, None],\n",
    "                                        \"min_samples_split\": [2, 4, 6, 8, 10, 12],\n",
    "                                        \"min_samples_leaf\": [1, 2, 3, 4, 5, 6],\n",
    "                                        \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                        \"bootstrap\": [True, False],\n",
    "                                        \"random_state\": [42]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVOMQzbwnJwq",
    "outputId": "192972eb-1dd8-4ca1-8e84-8e0a938e397e"
   },
   "outputs": [],
   "source": [
    "# model evaluation via m-times repeated k-fold cross validation\n",
    "start_time = time.time()\n",
    "\n",
    "# preallocate dictionary with cubic arrays used to save prediction values and performance scores over all m*k experiments\n",
    "scores_dict = create_scores_dict(k_splits = settings_dict[\"k_splits\"], \n",
    "                                 m_reps = settings_dict[\"m_reps\"], \n",
    "                                 len_y = settings_dict[\"n_molecules\"])\n",
    "\n",
    "# train and evaluate models\n",
    "for (m, k) in data_split_dictionary.keys():\n",
    "    \n",
    "    # extract indices for D_train and D_test for this data split\n",
    "    (ind_train_mols, ind_test_mols) = data_split_dictionary[(m,k)][0:2]\n",
    "    \n",
    "    # generate training- and test data (GNN + MLP)\n",
    "    graph_list_train = [graph_list[k] for k in ind_train_mols]\n",
    "    graph_list_test = [graph_list[k] for k in ind_test_mols]\n",
    "    \n",
    "    # find best hyperparameters via optuna and train associated model on training set (GNN + MLP)\n",
    "    (trained_best_gnn_model, \n",
    "     trained_best_mlp_model, \n",
    "     loss_curve_training_set) = train_gnn_mlps_via_optuna(graph_list_train,\n",
    "                                                          settings_dict[\"optuna_options\"],\n",
    "                                                          settings_dict[\"gin_hyperparameter_grid\"], \n",
    "                                                          settings_dict[\"mlp_hyperparameter_grid\"], \n",
    "                                                          settings_dict[\"train_hyperparameter_grid\"])\n",
    "    # plot learning curves (GNN + MLP)\n",
    "    plt.plot(loss_curve_training_set)\n",
    "    plt.title(\"loss curve on training set\")\n",
    "    plt.show()\n",
    "    \n",
    "    # extract learned features from molecular graphs via GNN\n",
    "    dataloader = GeometricDataLoader(dataset = graph_list, batch_size = len(graph_list), shuffle = False, drop_last = False)\n",
    "    trained_best_gnn_model.eval()\n",
    "    for batch in dataloader:\n",
    "        X_gnn = trained_best_gnn_model(batch.to('cuda' if torch.cuda.is_available() else 'cpu')).cpu().detach().numpy()\n",
    "           \n",
    "    # generate training- and test data       \n",
    "    X_gnn_train = X_gnn[ind_train_mols]\n",
    "    y_train = y[ind_train_mols]\n",
    "    \n",
    "    X_gnn_test = X_gnn[ind_test_mols]\n",
    "    y_test = y[ind_test_mols]\n",
    "    \n",
    "    # instantiate fresh model\n",
    "    regressor = RandomizedSearchCV(estimator = RandomForestRegressor(),\n",
    "                                   param_distributions = settings_dict[\"hyperparameter_grid\"],\n",
    "                                   n_iter = settings_dict[\"h_iters\"],\n",
    "                                   cv = settings_dict[\"j_splits\"],\n",
    "                                   scoring = settings_dict[\"random_search_scoring\"],\n",
    "                                   verbose = settings_dict[\"random_search_verbose\"],\n",
    "                                   random_state = settings_dict[\"random_search_random_state\"],\n",
    "                                   n_jobs = settings_dict[\"random_search_n_jobs\"])\n",
    "\n",
    "    # fit the model on the training data\n",
    "    regressor.fit(X_gnn_train, y_train)\n",
    "    \n",
    "    # create qsar predictions used to evaluate the model\n",
    "    y_pred = regressor.predict(X_gnn)\n",
    "    create_and_store_qsar_ac_pd_results(scores_dict, x_smiles, X_smiles_mmps,\n",
    "                                        y, y_mmps, y_mmps_pd, y_pred,\n",
    "                                        data_split_dictionary, m, k)\n",
    "    \n",
    "    # give feedback on completion of this subexperiment\n",
    "    print(\"Subexperiment \", (m,k), \" completed. \\n\")\n",
    "\n",
    "# save experimental results\n",
    "save_qsar_ac_pd_results(filepath, scores_dict)\n",
    "\n",
    "# save experimental settings\n",
    "settings_dict[\"runtime\"] = str(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n",
    "save_experimental_settings(filepath, settings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83rJJtNXnJwr",
    "outputId": "c5c932f4-ebc0-4380-fd3d-d1691277f003"
   },
   "outputs": [],
   "source": [
    "# display experimental results and settings\n",
    "display_experimental_results(filepath, decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GIN + kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzP-ACRRnJwp"
   },
   "outputs": [],
   "source": [
    "# set directory for saving of experimental results\n",
    "\n",
    "settings_dict[\"method_name\"] = \"gin_knn\"\n",
    "filepath = \"results/\" + settings_dict[\"target_name\"] + \"/\" + settings_dict[\"method_name\"] + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aQkXhCvnJwq"
   },
   "outputs": [],
   "source": [
    "# GNN + MLP: hyperparameter- and optuna settings\n",
    "\n",
    "settings_dict[\"optuna_options\"] = {\"h_iters\": 20,\n",
    "                                   \"frac_train\": 0.8,\n",
    "                                   \"data_splitting_seed\": 42,\n",
    "                                   \"performance_metric\": mean_absolute_error,\n",
    "                                   \"direction\": \"minimize\",\n",
    "                                   \"sampler\": optuna.samplers.TPESampler(), \n",
    "                                   \"pruner\": optuna.pruners.NopPruner()} \n",
    "\n",
    "settings_dict[\"gin_hyperparameter_grid\"] = {\"n_conv_layers\": [1, 2, 3],\n",
    "                                            \"input_dim\": [79],\n",
    "                                            \"hidden_dim\": [64, 128, 256],\n",
    "                                            \"mlp_n_hidden_layers\": [2],\n",
    "                                            \"mlp_hidden_activation\": [nn.ReLU()],\n",
    "                                            \"mlp_output_activation\": [nn.Identity()],\n",
    "                                            \"mlp_use_bias\": [True],\n",
    "                                            \"mlp_hidden_dropout_rate\": [0, 0.25],\n",
    "                                            \"mlp_hidden_batchnorm\": [True],\n",
    "                                            \"eps\": [0],\n",
    "                                            \"train_eps\": [False],\n",
    "                                            \"pooling_operation\": [global_max_pool]}\n",
    "\n",
    "settings_dict[\"mlp_hyperparameter_grid\"] = {\"architecture\": [arch(None, 1, w, d) for (w,d) in all_combs_list([None], [0])],\n",
    "                                            \"hidden_activation\": [nn.ReLU()],\n",
    "                                            \"output_activation\": [nn.Identity()],\n",
    "                                            \"use_bias\": [True],\n",
    "                                            \"hidden_dropout_rate\": [0],\n",
    "                                            \"hidden_batchnorm\": [True]}\n",
    "\n",
    "settings_dict[\"train_hyperparameter_grid\"] = {\"batch_size\": [32, 64, 128], \n",
    "                                              \"dataloader_shuffle\": [True],\n",
    "                                              \"dataloader_drop_last\":[True],\n",
    "                                              \"learning_rate\": [1e-2, 1e-3],\n",
    "                                              \"lr_lambda\": [lambda epoch: max(0.95**epoch, 1e-2), lambda epoch: max(0.99**epoch, 1e-2)],\n",
    "                                              \"weight_decay\": [0.1, 0.01],\n",
    "                                              \"num_epochs\": [500],\n",
    "                                              \"loss_function\": [nn.MSELoss()],\n",
    "                                              \"optimiser\": [torch.optim.AdamW],\n",
    "                                              \"performance_metrics\": [\"regression\"],\n",
    "                                              \"print_results_per_epochs\": [None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN: hyperparameter- and random search settings\n",
    "\n",
    "settings_dict[\"j_splits\"] = 5\n",
    "settings_dict[\"h_iters\"] = 10\n",
    "settings_dict[\"random_search_scoring\"] = \"neg_mean_absolute_error\"\n",
    "settings_dict[\"random_search_verbose\"] = 1\n",
    "settings_dict[\"random_search_random_state\"] = 42\n",
    "settings_dict[\"random_search_n_jobs\"] = -1\n",
    "settings_dict[\"hyperparameter_grid\"] = {\"n_neighbors\": list(range(1, 101)),\n",
    "                                        \"weights\": [\"uniform\", \"distance\"],\n",
    "                                        \"p\": [1, 2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVOMQzbwnJwq",
    "outputId": "192972eb-1dd8-4ca1-8e84-8e0a938e397e"
   },
   "outputs": [],
   "source": [
    "# model evaluation via m-times repeated k-fold cross validation\n",
    "start_time = time.time()\n",
    "\n",
    "# preallocate dictionary with cubic arrays used to save prediction values and performance scores over all m*k experiments\n",
    "scores_dict = create_scores_dict(k_splits = settings_dict[\"k_splits\"], \n",
    "                                 m_reps = settings_dict[\"m_reps\"], \n",
    "                                 len_y = settings_dict[\"n_molecules\"])\n",
    "\n",
    "# train and evaluate models\n",
    "for (m, k) in data_split_dictionary.keys():\n",
    "    \n",
    "    # extract indices for D_train and D_test for this data split\n",
    "    (ind_train_mols, ind_test_mols) = data_split_dictionary[(m,k)][0:2]\n",
    "    \n",
    "    # generate training- and test data (GNN + MLP)\n",
    "    graph_list_train = [graph_list[k] for k in ind_train_mols]\n",
    "    graph_list_test = [graph_list[k] for k in ind_test_mols]\n",
    "    \n",
    "    # find best hyperparameters via optuna and train associated model on training set (GNN + MLP)\n",
    "    (trained_best_gnn_model, \n",
    "     trained_best_mlp_model, \n",
    "     loss_curve_training_set) = train_gnn_mlps_via_optuna(graph_list_train,\n",
    "                                                          settings_dict[\"optuna_options\"],\n",
    "                                                          settings_dict[\"gin_hyperparameter_grid\"], \n",
    "                                                          settings_dict[\"mlp_hyperparameter_grid\"], \n",
    "                                                          settings_dict[\"train_hyperparameter_grid\"])\n",
    "    # plot learning curves (GNN + MLP)\n",
    "    plt.plot(loss_curve_training_set)\n",
    "    plt.title(\"loss curve on training set\")\n",
    "    plt.show()\n",
    "    \n",
    "    # extract learned features from molecular graphs via GNN\n",
    "    dataloader = GeometricDataLoader(dataset = graph_list, batch_size = len(graph_list), shuffle = False, drop_last = False)\n",
    "    trained_best_gnn_model.eval()\n",
    "    for batch in dataloader:\n",
    "        X_gnn = trained_best_gnn_model(batch.to('cuda' if torch.cuda.is_available() else 'cpu')).cpu().detach().numpy()\n",
    "           \n",
    "    # generate training- and test data       \n",
    "    X_gnn_train = X_gnn[ind_train_mols]\n",
    "    y_train = y[ind_train_mols]\n",
    "    \n",
    "    X_gnn_test = X_gnn[ind_test_mols]\n",
    "    y_test = y[ind_test_mols]\n",
    "    \n",
    "    # instantiate fresh model\n",
    "    regressor = RandomizedSearchCV(estimator = KNeighborsRegressor(),\n",
    "                                   param_distributions = settings_dict[\"hyperparameter_grid\"],\n",
    "                                   n_iter = settings_dict[\"h_iters\"],\n",
    "                                   cv = settings_dict[\"j_splits\"],\n",
    "                                   scoring = settings_dict[\"random_search_scoring\"],\n",
    "                                   verbose = settings_dict[\"random_search_verbose\"],\n",
    "                                   random_state = settings_dict[\"random_search_random_state\"],\n",
    "                                   n_jobs = settings_dict[\"random_search_n_jobs\"])\n",
    "\n",
    "    # fit the model on the training data\n",
    "    regressor.fit(X_gnn_train, y_train)\n",
    "    \n",
    "    # create qsar predictions used to evaluate the model\n",
    "    y_pred = regressor.predict(X_gnn)\n",
    "    create_and_store_qsar_ac_pd_results(scores_dict, x_smiles, X_smiles_mmps,\n",
    "                                        y, y_mmps, y_mmps_pd, y_pred,\n",
    "                                        data_split_dictionary, m, k)\n",
    "    \n",
    "    # give feedback on completion of this subexperiment\n",
    "    print(\"Subexperiment \", (m,k), \" completed. \\n\")\n",
    "\n",
    "# save experimental results\n",
    "save_qsar_ac_pd_results(filepath, scores_dict)\n",
    "\n",
    "# save experimental settings\n",
    "settings_dict[\"runtime\"] = str(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n",
    "save_experimental_settings(filepath, settings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83rJJtNXnJwr",
    "outputId": "c5c932f4-ebc0-4380-fd3d-d1691277f003"
   },
   "outputs": [],
   "source": [
    "# display experimental results and settings\n",
    "display_experimental_results(filepath, decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GIN + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzP-ACRRnJwp"
   },
   "outputs": [],
   "source": [
    "# set directory for saving of experimental results\n",
    "\n",
    "settings_dict[\"method_name\"] = \"gin_mlp\"\n",
    "filepath = \"results/\" + settings_dict[\"target_name\"] + \"/\" + settings_dict[\"method_name\"] + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aQkXhCvnJwq"
   },
   "outputs": [],
   "source": [
    "# GNN + MLP: hyperparameter- and optuna settings\n",
    "\n",
    "settings_dict[\"optuna_options\"] = {\"h_iters\": 20,\n",
    "                                   \"frac_train\": 0.8,\n",
    "                                   \"data_splitting_seed\": 42,\n",
    "                                   \"performance_metric\": mean_absolute_error,\n",
    "                                   \"direction\": \"minimize\",\n",
    "                                   \"sampler\": optuna.samplers.TPESampler(), \n",
    "                                   \"pruner\": optuna.pruners.NopPruner()} \n",
    "\n",
    "settings_dict[\"gin_hyperparameter_grid\"] = {\"n_conv_layers\": [1, 2, 3],\n",
    "                                            \"input_dim\": [79],\n",
    "                                            \"hidden_dim\": [64, 128, 256],\n",
    "                                            \"mlp_n_hidden_layers\": [2],\n",
    "                                            \"mlp_hidden_activation\": [nn.ReLU()],\n",
    "                                            \"mlp_output_activation\": [nn.Identity()],\n",
    "                                            \"mlp_use_bias\": [True],\n",
    "                                            \"mlp_hidden_dropout_rate\": [0, 0.25],\n",
    "                                            \"mlp_hidden_batchnorm\": [True],\n",
    "                                            \"eps\": [0],\n",
    "                                            \"train_eps\": [False],\n",
    "                                            \"pooling_operation\": [global_max_pool]}\n",
    "\n",
    "settings_dict[\"mlp_hyperparameter_grid\"] = {\"architecture\": [arch(None, 1, w, d) for (w,d) in all_combs_list([None], [1, 5, 10])],\n",
    "                                            \"hidden_activation\": [nn.ReLU()],\n",
    "                                            \"output_activation\": [nn.Identity()],\n",
    "                                            \"use_bias\": [True],\n",
    "                                            \"hidden_dropout_rate\": [0],\n",
    "                                            \"hidden_batchnorm\": [True]}\n",
    "\n",
    "settings_dict[\"train_hyperparameter_grid\"] = {\"batch_size\": [32, 64, 128], \n",
    "                                              \"dataloader_shuffle\": [True],\n",
    "                                              \"dataloader_drop_last\":[True],\n",
    "                                              \"learning_rate\": [1e-2, 1e-3],\n",
    "                                              \"lr_lambda\": [lambda epoch: max(0.95**epoch, 1e-2), lambda epoch: max(0.99**epoch, 1e-2)],\n",
    "                                              \"weight_decay\": [0.1, 0.01],\n",
    "                                              \"num_epochs\": [500],\n",
    "                                              \"loss_function\": [nn.MSELoss()],\n",
    "                                              \"optimiser\": [torch.optim.AdamW],\n",
    "                                              \"performance_metrics\": [\"regression\"],\n",
    "                                              \"print_results_per_epochs\": [None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVOMQzbwnJwq",
    "outputId": "192972eb-1dd8-4ca1-8e84-8e0a938e397e"
   },
   "outputs": [],
   "source": [
    "# model evaluation via m-times repeated k-fold cross validation\n",
    "start_time = time.time()\n",
    "\n",
    "# preallocate dictionary with cubic arrays used to save prediction values and performance scores over all m*k experiments\n",
    "scores_dict = create_scores_dict(k_splits = settings_dict[\"k_splits\"], \n",
    "                                 m_reps = settings_dict[\"m_reps\"], \n",
    "                                 len_y = settings_dict[\"n_molecules\"])\n",
    "\n",
    "# train and evaluate models\n",
    "for (m, k) in data_split_dictionary.keys():\n",
    "    \n",
    "    # extract indices for D_train and D_test for this data split\n",
    "    (ind_train_mols, ind_test_mols) = data_split_dictionary[(m,k)][0:2]\n",
    "    \n",
    "    # generate training- and test data\n",
    "    graph_list_train = [graph_list[k] for k in ind_train_mols]\n",
    "    y_train = y[ind_train_mols]\n",
    "    \n",
    "    graph_list_test = [graph_list[k] for k in ind_test_mols]\n",
    "    y_test = y[ind_test_mols]\n",
    "    \n",
    "    # find best hyperparameters via optuna and train associated model on training set\n",
    "    (trained_best_gnn_model, \n",
    "     trained_best_mlp_model, \n",
    "     loss_curve_training_set) = train_gnn_mlps_via_optuna(graph_list_train,\n",
    "                                                          settings_dict[\"optuna_options\"],\n",
    "                                                          settings_dict[\"gin_hyperparameter_grid\"], \n",
    "                                                          settings_dict[\"mlp_hyperparameter_grid\"], \n",
    "                                                          settings_dict[\"train_hyperparameter_grid\"])\n",
    "    # plot learning curves\n",
    "    plt.plot(loss_curve_training_set)\n",
    "    plt.title(\"loss curve on training set\")\n",
    "    plt.show()\n",
    "    \n",
    "    # create qsar predictions used to evaluate the model\n",
    "    dataloader = GeometricDataLoader(dataset = graph_list, batch_size = len(graph_list), shuffle = False, drop_last = False)\n",
    "    trained_best_gnn_model.eval()\n",
    "    trained_best_mlp_model.eval()\n",
    "    for batch in dataloader:\n",
    "        y_pred = trained_best_mlp_model(trained_best_gnn_model(batch.to('cuda' if torch.cuda.is_available() else 'cpu'))).cpu().detach().numpy()[:,0]\n",
    "    \n",
    "    create_and_store_qsar_ac_pd_results(scores_dict, x_smiles, X_smiles_mmps,\n",
    "                                        y, y_mmps, y_mmps_pd, y_pred,\n",
    "                                        data_split_dictionary, m, k)\n",
    "    \n",
    "    # give feedback on completion of this subexperiment\n",
    "    print(\"Subexperiment \", (m,k), \" completed. \\n\")\n",
    "\n",
    "# save experimental results\n",
    "save_qsar_ac_pd_results(filepath, scores_dict)\n",
    "\n",
    "# save experimental settings\n",
    "settings_dict[\"runtime\"] = str(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n",
    "save_experimental_settings(filepath, settings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83rJJtNXnJwr",
    "outputId": "c5c932f4-ebc0-4380-fd3d-d1691277f003"
   },
   "outputs": [],
   "source": [
    "# display experimental results and settings\n",
    "display_experimental_results(filepath, decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Visual Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "\n",
    "# targets: chembl_dopamine_d2, chembl_factor_xa, postera_sars_cov_2_mpro\n",
    "# tasks: \"qsar_train\", \"qsar_test\", \"ac_train\", \"ac_inter\", \"ac_test\", \"ac_cores\", \"pd_train\", \"pd_inter\", \"pd_test\", \"pd_cores\", \"pd_ac_pos_train\", \"pd_ac_pos_inter\", \"pd_ac_pos_test\", \"pd_ac_pos_cores\"\n",
    "# regression metrics: \"MAE\", \"MedAE\", \"RMSE\", \"MaxAE\", \"MSE\", \"Pearson's r\", \"R^2\", \"Test Cases\"\n",
    "# classification metrics: \"AUROC\", \"Accuracy\", \"Balanced Accuracy\", \"F1-Score\", \"MCC\", \"Sensitivity\", \"Specificity\", \"Precision\", \"Negative Predictive Value\", \"Test Cases\", \"Negative Test Cases\", \"Positive Test Cases\" \n",
    "\n",
    "visualise_results(target = \"chembl_dopamine_d2\",\n",
    "                  task_x = \"ac_test\",\n",
    "                  metric_x = \"MCC\",\n",
    "                  task_y = \"qsar_test\",\n",
    "                  metric_y = \"MAE\",\n",
    "                  y_axis_units = \" (pK$_{\\mathrm{i}}$ units)\",\n",
    "                  plot_legend = True,\n",
    "                  legend_loc = \"upper right\",\n",
    "                  plot_title = True,\n",
    "                  plot_x_label = True,\n",
    "                  plot_y_label = True,\n",
    "                  plot_error_bars = True,\n",
    "                  size = 14, \n",
    "                  filepath_to_save = \"figures/scatter.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "kee2e-GFy3LW",
    "goBvy2nHSEbU",
    "UkiCM3e9Gd7O",
    "ZnOzpAwWGf6x",
    "RUdRr7rTSEc6",
    "7HanBbXV2txi"
   ],
   "name": "Colab_LMP_ChEMBL_hERG_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
